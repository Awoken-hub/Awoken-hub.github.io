<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="不眠觉"><title>面部追踪 · 不眠觉的个人博客</title><meta name="description" content="本文概述了 Kinect 面部追踪的编程模型。

FaceFrame对象
FaceFrameResult对象
FaceFrame数据
边界框数据
点数据
面部旋转四元数
面部属性
数据库文件
性能考虑

FaceFrame对象FaceFrame类提供了一组关于被追踪者面部的基本信息，包括面部的位置、"><meta name="keywords" content="Kinect"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="mobile-web-app-capable" content="yes"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta id="site_data_static" data-url="/"><meta name="renderer" content="webkit"><link rel="shortcut icon" type="image/x-icon" href="/images/logo.png"><link rel="stylesheet" href="/js_complied/bundle.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin=""><style>:root { --normal-font-face: 'Noto Serif', 'Noto Serif SC', 'Noto Serif TC', 'Noto Serif JP', 'Noto Serif KR', 'Times New Roman', Times, serif; }</style><script src="/js_complied/bundle.js"></script><script>Utils.loadCSS("https://fonts.googleapis.com/css2?family=Noto+Serif+JP:wght@200..900&family=Noto+Serif+KR:wght@200..900&family=Noto+Serif+SC:wght@200..900&family=Noto+Serif+TC:wght@200..900&family=Noto+Serif:ital,wght@0,100..900;1,100..900&display=swap");
Utils.loadCSS("https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css");
Utils.loadCSS("/css/font-awesome.min.css");</script><meta name="generator" content="Hexo 7.3.0"></head><body class="post-page"><noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+JP:wght@200..900&amp;family=Noto+Serif+KR:wght@200..900&amp;family=Noto+Serif+SC:wght@200..900&amp;family=Noto+Serif+TC:wght@200..900&amp;family=Noto+Serif:ital,wght@0,100..900;1,100..900&amp;display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"></noscript><nav class="nav"><a href="/">首页</a>&nbsp;&nbsp;<a href="/archives">时间轴</a>&nbsp;&nbsp;<a href="/tags">标签</a>&nbsp;&nbsp;<a href="/search">搜索</a>&nbsp;&nbsp;<a href="javascript:SoSimple.darkLightToggle()">夜间/日间模式</a></nav><main class="main"><article class="post-container post-full"><header class="post-title"><h1>面部追踪</h1></header><section class="post-body"><p>本文概述了 Kinect 面部追踪的编程模型。</p>
<ul>
<li><code>FaceFrame</code>对象</li>
<li><code>FaceFrameResult</code>对象</li>
<li><code>FaceFrame</code>数据</li>
<li>边界框数据</li>
<li>点数据</li>
<li>面部旋转四元数</li>
<li>面部属性</li>
<li>数据库文件</li>
<li>性能考虑</li>
</ul>
<h1 id="FaceFrame对象"><a href="#FaceFrame对象" class="headerlink" title="FaceFrame对象"></a><code>FaceFrame</code>对象</h1><p><a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/previous-versions/windows/kinect/dn791576(v=ieb.10)"><code>FaceFrame</code>类</a>提供了一组关于被追踪者面部的基本信息，包括面部的位置、视线方向、基本表情信息以及是否佩戴眼镜。所有这些信息都可以在每个被追踪的人体上进行计算，最大有效距离为 3.5 米。</p>
<h1 id="FaceFrameResult对象"><a href="#FaceFrameResult对象" class="headerlink" title="FaceFrameResult对象"></a><code>FaceFrameResult</code>对象</h1><p><a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/previous-versions/windows/kinect/dn791565(v=ieb.10)"><code>FaceFrameResult</code>类</a>提供被追踪者面部基本信息，其数据在红外空间中计算，并映射到彩色空间。</p>
<h1 id="FaceFrame数据"><a href="#FaceFrame数据" class="headerlink" title="FaceFrame数据"></a><code>FaceFrame</code>数据</h1><p>为方便起见，所有<code>FaceFrame</code>类数据均在红外空间中计算，然后映射到彩色空间。这意味着像 <a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/previous-versions/windows/kinect/dn773608(v=ieb.10)"><code>FaceFrameResult.FaceBoundingBoxInColorSpace</code> 属性</a>的结果会受限于红外摄像头的视野。这也意味着在所有几乎所有红外流可见的照明条件下（如室内、夜晚等），都能返回所有信息。唯一的例外是 <code>RightEyeClosed</code> 和 <code>LeftEyeClosed</code> (<a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/previous-versions/windows/kinect/dn791599(v=ieb.10)"><code>FaceFrameResult.FaceProperties</code> 属性</a>)，它们依赖于彩色视频流，并且会受到不良光照条件的负面影响。</p>
<h1 id="边界框数据"><a href="#边界框数据" class="headerlink" title="边界框数据"></a>边界框数据</h1><p>面部检测结果包含一个<strong>边界框</strong>，这是一个由我们的面部检测算法确定的、包含用户头部的矩形。该边界框可通过 <a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/previous-versions/windows/kinect/dn773608(v=ieb.10)"><code>FaceFrameResult.FaceBoundingBoxInColorSpace</code> 属性</a>或 <a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/previous-versions/windows/kinect/dn773609(v=ieb.10)"><code>FaceFrameResult.FaceBoundingBoxInInfraredSpace</code> 属性</a>检索。</p>
<h1 id="点数据"><a href="#点数据" class="headerlink" title="点数据"></a>点数据</h1><p>点数据可通过 <code>FaceFrameResult.FacePointsInColorSpace</code> 属性或 <code>FaceFrameResult.FacePointsInInfraredSpace</code> 属性检索。这些位置也称为<strong>对齐点</strong>，代表了用户脸上的五个标志性位置。这五个点分别是：左眼、右眼、鼻子以及左右嘴角。</p>
<h1 id="面部旋转四元数"><a href="#面部旋转四元数" class="headerlink" title="面部旋转四元数"></a>面部旋转四元数</h1><p>通过 <a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/previous-versions/windows/kinect/dn791601(v=ieb.10)"><code>FaceRotationQuaternion</code> 属性</a>获得的<strong>头部枢轴点</strong>是计算出的头部中心，面部可围绕该点旋转。该点定义在 Kinect 人体坐标系中：原点位于相机的光学中心（传感器），Z 轴指向用户，Y 轴指向上方。测量单位为米。头部枢轴点与身体的头部关节点类似，但具有不同的垂直坐标（更适合作为旋转中心）。</p>
<h1 id="面部属性"><a href="#面部属性" class="headerlink" title="面部属性"></a>面部属性</h1><p><a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/previous-versions/windows/kinect/dn791599(v=ieb.10)"><code>FaceFrameResult.FaceProperties</code> 属性</a>返回一个只读的键-值对映射，提供有关用户面部外观或状态的信息。对于此映射中的每个条目，键是 <a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/previous-versions/windows/kinect/dn791600(v=ieb.10)"><code>FaceProperty</code> 枚举</a>的一个成员。下表列出了可用的属性。请注意，这些分类器的训练假设 Kinect 放置在内容源（电视等）的上方或下方，居中并朝向用户。</p>
<table>
<thead>
<tr>
<th>属性（Property）</th>
<th>描述（Description）</th>
</tr>
</thead>
<tbody><tr>
<td>Happy（高兴）</td>
<td>用户似乎在微笑，呈现出高兴的表情。这也会捕捉到大笑时的笑容。请注意，有些用户即使不高兴也看起来像在笑，因此这不应被视为情绪的精确转换。</td>
</tr>
<tr>
<td>Engaged（投入）</td>
<td>结合了 <code>LookingAway</code> 和 <code>EyeClosed</code> 的结果，以确定用户是否专注于内容。</td>
</tr>
<tr>
<td>WearingGlasses（戴眼镜）</td>
<td>用户戴着眼镜。</td>
</tr>
<tr>
<td>LeftEyeClosed（左眼闭合）</td>
<td>用户的左眼是闭着的。</td>
</tr>
<tr>
<td>RightEyeClosed（右眼闭合）</td>
<td>用户的右眼是闭着的。</td>
</tr>
<tr>
<td>MouthOpen（嘴巴张开）</td>
<td>用户的嘴巴是张开的。</td>
</tr>
<tr>
<td>MouthMoved（嘴巴移动）</td>
<td>用户的嘴巴移动了。这是唯一一个需要跨帧结果才能做出准确判断的属性。如果用户的头部大部分时间保持静止，此功能效果最佳。</td>
</tr>
<tr>
<td>LookingAway（视线移开）</td>
<td>确定用户是否将视线从内容上移开。该检测不够精细，无法检测到轻微的视线转移，但可以检测到较大的头部运动，例如转头与人交谈或低头查看手机。</td>
</tr>
</tbody></table>
<p>对于 <a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/previous-versions/windows/kinect/dn791599(v=ieb.10)"><code>FaceFrameResult.FaceProperties</code> 属性</a>映射中的每个条目，其值是 <a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/previous-versions/windows/kinect/dn758566(v=ieb.10)"><code>DetectionResult</code> 枚举</a>的一个成员，表示系统对相应面部属性的检测结果。下表描述了如何调整和计算这些结果。</p>
<table>
<thead>
<tr>
<th>检测结果 (DetectionResult)</th>
<th>描述 (Description)</th>
</tr>
</thead>
<tbody><tr>
<td>Yes (是)</td>
<td>我们非常确定该属性为真，你可以基于此结果采取决定性操作。</td>
</tr>
<tr>
<td>No (否)</td>
<td>我们非常确定该属性为假，你可以基于此结果采取决定性操作。</td>
</tr>
<tr>
<td>Maybe (可能)</td>
<td>我们相当确定该属性为真。你可以基于此结果奖励用户或给予正向反馈。对于大多数属性，你可以由此推断相应的动作幅度较小。</td>
</tr>
<tr>
<td>Unknown (未知)</td>
<td>我们没有足够的信息来做出判断。这通常是因为用户将脸转向远离传感器的方向，而我们也不想给出一个糟糕的结果。</td>
</tr>
</tbody></table>
<h1 id="数据库文件"><a href="#数据库文件" class="headerlink" title="数据库文件"></a>数据库文件</h1><p>每个使用 <code>Microsoft.Kinect.Face.dll</code> 的应用程序<strong>必须</strong>与随同 <code>Microsoft.Kinect.Face.dll</code> 一起发布的 <code>NuiDatabase</code> 文件夹打包在一起。<code>Microsoft.Kinect.Face.dll</code>仅保证与它一同发布的特定 <code>NuiDatabase</code> 文件夹一起正常工作。面部 API 在初始化时会从 <code>NuiDatabase</code> 文件夹中加载数据库文件，并且会在 <code>Microsoft.Kinect.Face.dll</code> 相同的路径下查找该文件夹。</p>
<h1 id="性能考虑"><a href="#性能考虑" class="headerlink" title="性能考虑"></a>性能考虑</h1><p>如果要在事件处理程序中执行长时间运行的任务（耗时超过单帧到达的时间），则必须在执行任务之前获取所有相关的帧引用。如果未事先获取引用，帧数据可能会被覆盖，获取引用或数据的调用将返回 <code>null</code>。</p>
<p>通常，最好避免在事件处理程序中执行长时间运行的任务，应使用独立线程来处理。</p>
</section><section class="post-meta"><span class="info"><i class="fa fa-calendar"></i> <span class="date">2025-09-12</span>  </span><span class="info"><i class="fa fa-tag"></i> <a href="/tags/Kinect/" title="Kinect">Kinect</a>  </span></section></article><p class="pagination"><a href="/2025/09/12/%E9%AB%98%E6%B8%85%E9%9D%A2%E9%83%A8%E8%BF%BD%E8%B8%AA/" title="高清面部追踪">上一篇</a><span>  </span><a href="/2025/09/12/%E5%9D%90%E6%A0%87%E6%98%A0%E5%B0%84/" title="坐标映射">下一篇</a></p></main><footer class="footer"><br></footer></body></html>